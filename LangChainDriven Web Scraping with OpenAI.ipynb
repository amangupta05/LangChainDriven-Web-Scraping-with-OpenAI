{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangchainDriven Web scraping with OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain import OpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  \n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables and Initialize Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amang\\AppData\\Local\\Temp\\ipykernel_19308\\3873068739.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  openai = OpenAI(api_key=OPENAI_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "openai = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function to scrape the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scrape_website(url):\n",
    "    try:\n",
    "        loader = WebBaseLoader(url)\n",
    "        documents = loader.load()\n",
    "        if documents:\n",
    "            content = \" \".join([doc.page_content for doc in documents])\n",
    "            return content\n",
    "        else:\n",
    "            print(\"No documents found.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while scraping the website: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Functions: Divide Text into Chunks, Convert Text Chunks into Vector Embeddings, and Store Vectors in a Vector Store Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def text_to_vectors(chunks):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectors = embeddings.embed_documents(chunks)  \n",
    "    return vectors, embeddings  \n",
    "\n",
    "\n",
    "def store_vectors(chunks, embeddings):\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a retrieval QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_retrieval_qa_chain(vector_store):\n",
    "    retrieval_qa = RetrievalQA.from_chain_type(\n",
    "        llm=openai, \n",
    "        chain_type=\"stuff\",  \n",
    "        retriever=vector_store.as_retriever()\n",
    "    )\n",
    "    return retrieval_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_llm_response(query, retrieval_qa):\n",
    "    response = retrieval_qa.invoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entered website URL to scrape: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "Entered querry: what is AI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Text:\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Artificial intelligence - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Create account Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tPages for logged out editors learn more\n",
      "\n",
      "\n",
      "\n",
      "ContributionsTalk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Top)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Goals\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle Goals subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.1\n",
      "Reasoning and problem-solving\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.2\n",
      "Knowledge representation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.3\n",
      "Planning and decision-making\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.4\n",
      "Learning\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.5\n",
      "Natural language processing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.6\n",
      "Perception\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.7\n",
      "Social intelligence\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.8\n",
      "General intelligence\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Techniques\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle Techniques subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2.1\n",
      "Search and\n",
      "Number of chunks created: 389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amang\\miniconda3\\envs\\langchainEnv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\amang\\miniconda3\\envs\\langchainEnv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors created: 389\n",
      "Response:\n",
      " {'query': 'what is AI?', 'result': ' AI stands for Artificial Intelligence and is a field of research in computer science that aims to develop and study methods and software that enable machines to perceive their environment and use learning and intelligence to achieve defined goals. It involves the ability of systems to synthesize information and make decisions, similar to how biological intelligence functions. '}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = input(\"Enter the website URL to scrape: \")  # Ask the user for the website URL\n",
    "    scraped_text = scrape_website(url)\n",
    "\n",
    "    if scraped_text is None or scraped_text.strip() == \"\":\n",
    "        print(\"Failed to retrieve the website content.\")\n",
    "    else:\n",
    "        print(\"Scraped Text:\\n\", scraped_text[:1000])  # Print the first 1000 characters of the scraped text\n",
    "        \n",
    "        chunks = chunk_text(scraped_text)\n",
    "        print(f\"Number of chunks created: {len(chunks)}\")  # Debugging print\n",
    "        vectors, embeddings = text_to_vectors(chunks)  # Get vectors and embeddings\n",
    "        print(f\"Number of vectors created: {len(vectors)}\")  # Debugging print\n",
    "        \n",
    "        vector_store = store_vectors(chunks, embeddings)  # Pass embeddings for FAISS\n",
    "        \n",
    "        query = input(\"Enter your query: \")\n",
    "        retrieval_qa = create_retrieval_qa_chain(vector_store)\n",
    "        \n",
    "        response = get_llm_response(query, retrieval_qa)\n",
    "        print(\"Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is AI?',\n",
       " 'result': ' AI stands for Artificial Intelligence and is a field of research in computer science that aims to develop and study methods and software that enable machines to perceive their environment and use learning and intelligence to achieve defined goals. It involves the ability of systems to synthesize information and make decisions, similar to how biological intelligence functions. '}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
